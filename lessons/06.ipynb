{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6주차: 기초 머신러닝 - 분류\n",
    "\n",
    "## 학습 목표\n",
    "- 머신러닝의 기본 개념과 지도학습을 이해하자\n",
    "- Train/Test 분할과 모델 평가 방법을 배우자\n",
    "- K-Nearest Neighbors와 Decision Tree로 음원 장르 분류를 해보자\n",
    "- 정확도, 혼동행렬로 모델 성능을 평가해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 스타일 설정\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비\n",
    "\n",
    "### 1.1 음원 데이터셋 생성\n",
    "\n",
    "머신러닝 실습을 위한 음원 데이터를 만들어보자.\n",
    "장르별로 다른 특징을 가지도록 설계하여 분류 모델이 학습할 수 있도록 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 설정으로 재현 가능한 결과\n",
    "np.random.seed(42)\n",
    "n_tracks = 1200\n",
    "\n",
    "# 장르 정의 (분류하기 쉽게 4개로 축소)\n",
    "genres = ['Pop', 'Rock', 'Electronic', 'Classical']\n",
    "genre_weights = [0.3, 0.25, 0.25, 0.2]\n",
    "\n",
    "# 기본 데이터 구조\n",
    "music_data = pd.DataFrame({\n",
    "    'track_id': [f'T{i:04d}' for i in range(n_tracks)],\n",
    "    'genre': np.random.choice(genres, n_tracks, p=genre_weights)\n",
    "})\n",
    "\n",
    "# 음향 특징들 생성 (장르별로 뚜렷한 특성 부여)\n",
    "for genre in genres:\n",
    "    mask = music_data['genre'] == genre\n",
    "    count = mask.sum()\n",
    "    \n",
    "    if genre == 'Pop':\n",
    "        music_data.loc[mask, 'tempo'] = np.clip(np.random.normal(120, 10, count), 80, 160)\n",
    "        music_data.loc[mask, 'energy'] = np.clip(np.random.normal(0.7, 0.15, count), 0, 1)\n",
    "        music_data.loc[mask, 'danceability'] = np.clip(np.random.normal(0.75, 0.1, count), 0, 1)\n",
    "        music_data.loc[mask, 'valence'] = np.clip(np.random.normal(0.6, 0.2, count), 0, 1)\n",
    "        \n",
    "    elif genre == 'Rock':\n",
    "        music_data.loc[mask, 'tempo'] = np.clip(np.random.normal(130, 15, count), 80, 160)\n",
    "        music_data.loc[mask, 'energy'] = np.clip(np.random.normal(0.8, 0.1, count), 0, 1)\n",
    "        music_data.loc[mask, 'danceability'] = np.clip(np.random.normal(0.5, 0.15, count), 0, 1)\n",
    "        music_data.loc[mask, 'valence'] = np.clip(np.random.normal(0.5, 0.2, count), 0, 1)\n",
    "        \n",
    "    elif genre == 'Electronic':\n",
    "        music_data.loc[mask, 'tempo'] = np.clip(np.random.normal(128, 12, count), 80, 160)\n",
    "        music_data.loc[mask, 'energy'] = np.clip(np.random.normal(0.85, 0.1, count), 0, 1)\n",
    "        music_data.loc[mask, 'danceability'] = np.clip(np.random.normal(0.8, 0.1, count), 0, 1)\n",
    "        music_data.loc[mask, 'valence'] = np.clip(np.random.normal(0.65, 0.15, count), 0, 1)\n",
    "        \n",
    "    else:  # Classical\n",
    "        music_data.loc[mask, 'tempo'] = np.clip(np.random.normal(90, 20, count), 80, 160)\n",
    "        music_data.loc[mask, 'energy'] = np.clip(np.random.normal(0.3, 0.15, count), 0, 1)\n",
    "        music_data.loc[mask, 'danceability'] = np.clip(np.random.normal(0.2, 0.1, count), 0, 1)\n",
    "        music_data.loc[mask, 'valence'] = np.clip(np.random.normal(0.4, 0.15, count), 0, 1)\n",
    "\n",
    "print(f\"음원 데이터셋 생성 완료!\")\n",
    "print(f\"총 {n_tracks}개 트랙, {len(genres)}개 장르\")\n",
    "print(f\"\\n데이터 샘플:\")\n",
    "print(music_data.head())\n",
    "\n",
    "print(f\"\\n장르별 분포:\")\n",
    "print(music_data['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 데이터 탐색\n",
    "\n",
    "머신러닝을 하기 전에 항상 데이터를 먼저 살펴보자.\n",
    "장르별로 특징이 어떻게 다른지 시각화해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 장르별 특징 분포 시각화\n",
    "features = ['tempo', 'energy', 'danceability', 'valence']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "colors = {'Pop': 'red', 'Rock': 'blue', 'Electronic': 'green', 'Classical': 'purple'}\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    for genre in genres:\n",
    "        data = music_data[music_data['genre'] == genre][feature]\n",
    "        axes[idx].hist(data, alpha=0.6, label=genre, color=colors[genre], bins=20, density=True)\n",
    "    \n",
    "    axes[idx].set_title(f'{feature.title()} Distribution by Genre')\n",
    "    axes[idx].set_xlabel(feature.title())\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 장르별 평균값 확인\n",
    "print(\"장르별 특징 평균값:\")\n",
    "print(music_data.groupby('genre')[features].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 머신러닝 기초 개념\n",
    "\n",
    "### 2.1 지도학습이란?\n",
    "\n",
    "**지도학습(Supervised Learning)**은 정답(레이블)이 있는 데이터로 모델을 학습시키는 방법이다.\n",
    "\n",
    "**분류(Classification)의 목표:**\n",
    "- 입력: 음원의 특징들 (tempo, energy, danceability, valence)\n",
    "- 출력: 장르 예측 (Pop, Rock, Electronic, Classical)\n",
    "\n",
    "**학습 과정:**\n",
    "1. **훈련 데이터**로 모델 학습\n",
    "2. **테스트 데이터**로 모델 평가\n",
    "3. 성능이 좋으면 새로운 데이터 예측에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train/Test 분할\n",
    "\n",
    "**왜 데이터를 나눌까?**\n",
    "- **훈련 데이터**: 모델이 학습하는 데이터\n",
    "- **테스트 데이터**: 모델 성능을 평가하는 데이터 (모델이 본 적 없는 데이터)\n",
    "\n",
    "**일반적인 분할 비율:**\n",
    "- 훈련: 70-80%\n",
    "- 테스트: 20-30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징과 타겟 분리\n",
    "X = music_data[features]  # 특징들\n",
    "y = music_data['genre']   # 타겟 (정답)\n",
    "\n",
    "print(\"데이터 형태:\")\n",
    "print(f\"특징 행렬 X: {X.shape}\")\n",
    "print(f\"타겟 벡터 y: {y.shape}\")\n",
    "\n",
    "# 데이터 분할 (80% 훈련, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n데이터 분할 완료:\")\n",
    "print(f\"훈련 데이터: {X_train.shape[0]}개 ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"테스트 데이터: {X_test.shape[0]}개 ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# 분할 후 장르별 분포 확인\n",
    "print(f\"\\n훈련 데이터 장르 분포:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\n테스트 데이터 장르 분포:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Nearest Neighbors (KNN)\n",
    "\n",
    "### 3.1 KNN의 직관적 이해\n",
    "\n",
    "**KNN의 아이디어:**\n",
    "\"비슷한 특징을 가진 음원들은 같은 장르일 가능성이 높다\"\n",
    "\n",
    "**작동 원리:**\n",
    "1. 새로운 음원이 들어오면\n",
    "2. 가장 가까운 K개의 이웃을 찾는다\n",
    "3. 이웃들의 장르 중 가장 많은 것으로 예측한다\n",
    "\n",
    "**K값의 영향:**\n",
    "- **K=1**: 가장 가까운 1개만 봄 (과적합 위험)\n",
    "- **K=큰값**: 많은 이웃을 봄 (과소적합 위험)\n",
    "- **보통 홀수값 사용** (동점 방지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 모델 생성 및 학습\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"KNN 정확도: {accuracy_knn:.3f} ({accuracy_knn*100:.1f}%)\")\n",
    "\n",
    "# 예측 예시\n",
    "print(f\"\\n예측 예시 (처음 10개):\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    '실제': y_test.iloc[:10].values,\n",
    "    'KNN예측': y_pred_knn[:10],\n",
    "    '일치': y_test.iloc[:10].values == y_pred_knn[:10]\n",
    "})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 최적의 K값 찾기\n",
    "\n",
    "다양한 K값을 시도해보고 가장 좋은 성능을 내는 K를 찾아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 K값에 대한 성능 평가\n",
    "k_values = range(1, 21)\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn_temp = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_temp.fit(X_train, y_train)\n",
    "    y_pred_temp = knn_temp.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred_temp)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# 최적의 K값 찾기\n",
    "best_k = k_values[np.argmax(accuracies)]\n",
    "best_accuracy = max(accuracies)\n",
    "\n",
    "print(f\"최적의 K값: {best_k}\")\n",
    "print(f\"최고 정확도: {best_accuracy:.3f} ({best_accuracy*100:.1f}%)\")\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, accuracies, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axvline(best_k, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Best K={best_k}')\n",
    "plt.axhline(best_accuracy, color='red', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN Performance by K Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 정확도 분포\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(accuracies, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(best_accuracy, color='red', linestyle='--', linewidth=2,\n",
    "           label=f'Best: {best_accuracy:.3f}')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Accuracy Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 성능 상위 5개 K값\n",
    "top_k_indices = np.argsort(accuracies)[-5:][::-1]\n",
    "print(f\"\\n상위 5개 K값:\")\n",
    "for i, idx in enumerate(top_k_indices):\n",
    "    k_val = k_values[idx]\n",
    "    acc = accuracies[idx]\n",
    "    print(f\"{i+1}. K={k_val}: {acc:.3f} ({acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree (의사결정나무)\n",
    "\n",
    "### 4.1 Decision Tree의 직관적 이해\n",
    "\n",
    "**Decision Tree의 아이디어:**\n",
    "\"일련의 질문을 통해 장르를 결정하자\"\n",
    "\n",
    "**예시 질문들:**\n",
    "- Energy > 0.6인가? → Yes: Rock/Electronic 가능성 ↑\n",
    "- Danceability > 0.7인가? → Yes: Pop/Electronic 가능성 ↑\n",
    "- Tempo < 100인가? → Yes: Classical 가능성 ↑\n",
    "\n",
    "**장점:**\n",
    "- **해석 가능**: 의사결정 과정을 시각적으로 볼 수 있음\n",
    "- **빠른 예측**: 몇 번의 질문만으로 결정\n",
    "- **비선형 관계**: 복잡한 패턴도 학습 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 모델 생성 및 학습\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=5,        # 트리 깊이 제한 (과적합 방지)\n",
    "    min_samples_split=20,  # 분할을 위한 최소 샘플 수\n",
    "    min_samples_leaf=10,   # 리프 노드의 최소 샘플 수\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree 정확도: {accuracy_dt:.3f} ({accuracy_dt*100:.1f}%)\")\n",
    "\n",
    "# 특징 중요도 확인\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': dt.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n특징 중요도:\")\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:12}: {row['importance']:.3f} ({'='*int(row['importance']*50)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree 시각화\n",
    "\n",
    "실제 모델이 어떤 질문들을 통해 장르를 분류하는지 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 시각화\n",
    "plt.figure(figsize=(20, 12))\n",
    "plot_tree(dt, \n",
    "          feature_names=features,\n",
    "          class_names=genres,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Visualization', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 특징 중요도 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "bars = plt.bar(feature_importance['feature'], feature_importance['importance'],\n",
    "               color=['skyblue', 'lightgreen', 'lightcoral', 'gold'], alpha=0.7)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance in Decision Tree')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 막대 위에 값 표시\n",
    "for bar, importance in zip(bars, feature_importance['importance']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{importance:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 원형 차트로도 표시\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(feature_importance['importance'], \n",
    "        labels=feature_importance['feature'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "plt.title('Feature Importance Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n해석:\")\n",
    "most_important = feature_importance.iloc[0]\n",
    "print(f\"가장 중요한 특징: {most_important['feature']} ({most_important['importance']:.3f})\")\n",
    "print(f\"이 특징이 장르 분류에 가장 큰 영향을 미칩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 성능 평가\n",
    "\n",
    "### 5.1 정확도와 혼동행렬\n",
    "\n",
    "**정확도(Accuracy)**: 전체 예측 중 맞힌 비율\n",
    "- 정확도 = (올바른 예측 수) / (전체 예측 수)\n",
    "\n",
    "**혼동행렬(Confusion Matrix)**: 실제 vs 예측의 상세한 분석\n",
    "- 어떤 장르를 어떤 장르로 잘못 분류했는지 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 KNN 모델로 다시 학습\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_best.fit(X_train, y_train)\n",
    "y_pred_knn_best = knn_best.predict(X_test)\n",
    "\n",
    "# 두 모델의 성능 비교\n",
    "print(\"모델 성능 비교:\")\n",
    "print(f\"KNN (K={best_k}): {accuracy_score(y_test, y_pred_knn_best):.3f} ({accuracy_score(y_test, y_pred_knn_best)*100:.1f}%)\")\n",
    "print(f\"Decision Tree: {accuracy_dt:.3f} ({accuracy_dt*100:.1f}%)\")\n",
    "\n",
    "# 혼동행렬 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# KNN 혼동행렬\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn_best)\n",
    "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=genres, yticklabels=genres, ax=axes[0])\n",
    "axes[0].set_title(f'KNN Confusion Matrix\\n(Accuracy: {accuracy_score(y_test, y_pred_knn_best):.3f})')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Decision Tree 혼동행렬\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Greens',\n",
    "           xticklabels=genres, yticklabels=genres, ax=axes[1])\n",
    "axes[1].set_title(f'Decision Tree Confusion Matrix\\n(Accuracy: {accuracy_dt:.3f})')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 장르별 정확도 분석\n",
    "print(f\"\\n장르별 성능 분석 (KNN):\")\n",
    "knn_report = classification_report(y_test, y_pred_knn_best, output_dict=True)\n",
    "for genre in genres:\n",
    "    precision = knn_report[genre]['precision']\n",
    "    recall = knn_report[genre]['recall']\n",
    "    f1 = knn_report[genre]['f1-score']\n",
    "    print(f\"{genre:10} - Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 실제 예측 해보기\n",
    "\n",
    "새로운 음원 데이터를 만들어서 우리 모델이 어떻게 예측하는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 음원 데이터 생성 (각 장르의 전형적인 특징)\n",
    "new_tracks = pd.DataFrame({\n",
    "    'tempo': [125, 140, 128, 85],\n",
    "    'energy': [0.7, 0.8, 0.85, 0.3],\n",
    "    'danceability': [0.75, 0.5, 0.8, 0.2],\n",
    "    'valence': [0.6, 0.5, 0.65, 0.4]\n",
    "}, index=['Track_A', 'Track_B', 'Track_C', 'Track_D'])\n",
    "\n",
    "print(\"새로운 음원들:\")\n",
    "print(new_tracks)\n",
    "\n",
    "# KNN과 Decision Tree로 예측\n",
    "knn_predictions = knn_best.predict(new_tracks)\n",
    "dt_predictions = dt.predict(new_tracks)\n",
    "\n",
    "# 예측 확률도 확인 (KNN)\n",
    "knn_probs = knn_best.predict_proba(new_tracks)\n",
    "dt_probs = dt.predict_proba(new_tracks)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"\\n예측 결과:\")\n",
    "results_df = pd.DataFrame({\n",
    "    'KNN_예측': knn_predictions,\n",
    "    'DT_예측': dt_predictions,\n",
    "    'KNN_신뢰도': [max(prob) for prob in knn_probs],\n",
    "    'DT_신뢰도': [max(prob) for prob in dt_probs]\n",
    "}, index=new_tracks.index)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# 각 트랙별 상세 확률 분포\n",
    "print(f\"\\n장르별 예측 확률 (KNN):\")\n",
    "prob_df = pd.DataFrame(knn_probs, \n",
    "                      columns=knn_best.classes_, \n",
    "                      index=new_tracks.index)\n",
    "print(prob_df.round(3))\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, track in enumerate(new_tracks.index):\n",
    "    probs = knn_probs[idx]\n",
    "    bars = axes[idx].bar(genres, probs, color=['red', 'blue', 'green', 'purple'], alpha=0.7)\n",
    "    axes[idx].set_title(f'{track} - KNN Prediction: {knn_predictions[idx]}')\n",
    "    axes[idx].set_ylabel('Probability')\n",
    "    axes[idx].set_ylim(0, 1)\n",
    "    \n",
    "    # 막대 위에 확률 표시\n",
    "    for bar, prob in zip(bars, probs):\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                      f'{prob:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n해석:\")\n",
    "for i, track in enumerate(new_tracks.index):\n",
    "    prediction = knn_predictions[i]\n",
    "    confidence = max(knn_probs[i])\n",
    "    print(f\"{track}: {prediction} ({confidence:.1%} 확신)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 개선하기\n",
    "\n",
    "### 6.1 특징 정규화 (Feature Scaling)\n",
    "\n",
    "**왜 정규화가 필요한가?**\n",
    "- KNN은 거리를 기반으로 하므로 특징들의 스케일이 다르면 문제가 생긴다\n",
    "- 예: tempo(80-160) vs energy(0-1) → tempo가 거리에 더 큰 영향\n",
    "\n",
    "**StandardScaler**: 평균 0, 표준편차 1로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"정규화 전후 비교:\")\n",
    "print(\"\\n정규화 전:\")\n",
    "print(pd.DataFrame(X_train).describe().round(3))\n",
    "print(\"\\n정규화 후:\")\n",
    "print(pd.DataFrame(X_train_scaled, columns=features).describe().round(3))\n",
    "\n",
    "# 정규화된 데이터로 KNN 재학습\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_knn_scaled = knn_scaled.predict(X_test_scaled)\n",
    "\n",
    "accuracy_knn_scaled = accuracy_score(y_test, y_pred_knn_scaled)\n",
    "\n",
    "print(f\"\\n성능 비교:\")\n",
    "print(f\"KNN (정규화 전): {accuracy_score(y_test, y_pred_knn_best):.3f} ({accuracy_score(y_test, y_pred_knn_best)*100:.1f}%)\")\n",
    "print(f\"KNN (정규화 후): {accuracy_knn_scaled:.3f} ({accuracy_knn_scaled*100:.1f}%)\")\n",
    "print(f\"Decision Tree:    {accuracy_dt:.3f} ({accuracy_dt*100:.1f}%)\")\n",
    "\n",
    "improvement = accuracy_knn_scaled - accuracy_score(y_test, y_pred_knn_best)\n",
    "if improvement > 0:\n",
    "    print(f\"\\n정규화로 성능 개선: +{improvement:.3f} (+{improvement*100:.1f}%p)\")\n",
    "else:\n",
    "    print(f\"\\n정규화 효과: {improvement:.3f} ({improvement*100:.1f}%p)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 교차 검증 (Cross Validation)\n",
    "\n",
    "**교차 검증이란?**\n",
    "- 데이터를 여러 번 나누어 더 신뢰할 수 있는 성능 평가\n",
    "- 5-Fold CV: 데이터를 5등분하여 5번 평가 후 평균\n",
    "\n",
    "**장점:**\n",
    "- 더 안정적인 성능 추정\n",
    "- 과적합 여부 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증으로 성능 평가\n",
    "print(\"5-Fold 교차 검증 수행 중...\")\n",
    "\n",
    "# KNN (정규화 적용)\n",
    "knn_cv_scores = cross_val_score(knn_scaled, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Decision Tree\n",
    "dt_cv_scores = cross_val_score(dt, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"\\n교차 검증 결과:\")\n",
    "print(f\"\\nKNN (K={best_k}, 정규화):\")\n",
    "print(f\"  각 Fold 점수: {knn_cv_scores.round(3)}\")\n",
    "print(f\"  평균: {knn_cv_scores.mean():.3f} ± {knn_cv_scores.std():.3f}\")\n",
    "\n",
    "print(f\"\\nDecision Tree:\")\n",
    "print(f\"  각 Fold 점수: {dt_cv_scores.round(3)}\")\n",
    "print(f\"  평균: {dt_cv_scores.mean():.3f} ± {dt_cv_scores.std():.3f}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "models = ['KNN\\n(Scaled)', 'Decision\\nTree']\n",
    "means = [knn_cv_scores.mean(), dt_cv_scores.mean()]\n",
    "stds = [knn_cv_scores.std(), dt_cv_scores.std()]\n",
    "\n",
    "bars = plt.bar(models, means, yerr=stds, capsize=5,\n",
    "               color=['skyblue', 'lightgreen'], alpha=0.7, edgecolor='black')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Cross-Validation Results')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 막대 위에 값 표시\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.02,\n",
    "            f'{mean:.3f}\\n±{std:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 점수 분포\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([knn_cv_scores, dt_cv_scores], labels=models)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('CV Score Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 성능 평가\n",
    "print(f\"\\n최종 성능 종합:\")\n",
    "print(f\"{'Model':<15} {'Test Accuracy':<15} {'CV Mean':<10} {'CV Std':<10}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'KNN (Scaled)':<15} {accuracy_knn_scaled:<15.3f} {knn_cv_scores.mean():<10.3f} {knn_cv_scores.std():<10.3f}\")\n",
    "print(f\"{'Decision Tree':<15} {accuracy_dt:<15.3f} {dt_cv_scores.mean():<10.3f} {dt_cv_scores.std():<10.3f}\")\n",
    "\n",
    "# 최고 모델 선정\n",
    "if accuracy_knn_scaled > accuracy_dt:\n",
    "    print(f\"\\nBest Model: KNN (K={best_k}, with scaling)\")\n",
    "    print(f\"   Test Accuracy: {accuracy_knn_scaled:.3f} ({accuracy_knn_scaled*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\nBest Model: Decision Tree\")\n",
    "    print(f\"   Test Accuracy: {accuracy_dt:.3f} ({accuracy_dt*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오늘 배운 머신러닝 개념 정리\n",
    "\n",
    "### 지도학습 기초\n",
    "- **분류 문제**: 입력 특징 → 카테고리 예측\n",
    "- **Train/Test 분할**: 학습용 데이터와 평가용 데이터 분리\n",
    "- **과적합/과소적합**: 모델 복잡도와 성능의 균형\n",
    "\n",
    "### K-Nearest Neighbors (KNN)\n",
    "- **직관적**: \"비슷한 것끼리 같은 그룹\"\n",
    "- **K값 조정**: 이웃 개수가 성능에 큰 영향\n",
    "- **거리 기반**: 특징 정규화가 중요\n",
    "\n",
    "### Decision Tree\n",
    "- **해석 가능**: 의사결정 과정을 시각화\n",
    "- **특징 중요도**: 어떤 특징이 중요한지 확인 가능\n",
    "- **과적합 주의**: 트리 깊이 제한 필요\n",
    "\n",
    "### 모델 평가\n",
    "- **정확도**: 전체 중 맞힌 비율\n",
    "- **혼동행렬**: 어떤 실수를 했는지 상세 분석\n",
    "- **교차 검증**: 더 신뢰할 수 있는 성능 평가\n",
    "\n",
    "### 특징 전처리\n",
    "- **정규화**: 특징들의 스케일 통일\n",
    "- **StandardScaler**: 평균 0, 표준편차 1로 변환\n",
    "\n",
    "### 핵심 포인트\n",
    "- **데이터 탐색**이 먼저: 시각화로 패턴 파악\n",
    "- **여러 모델 비교**: 문제에 따라 최적 모델이 다름\n",
    "- **성능 vs 해석성**: KNN은 성능, Decision Tree는 해석성\n",
    "- **검증의 중요성**: 교차 검증으로 신뢰성 확보"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
